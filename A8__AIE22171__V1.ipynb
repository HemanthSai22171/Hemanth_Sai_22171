{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Node Feature: Open\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-9))  # Added epsilon for numerical stability\n",
    "    return entropy\n",
    "\n",
    "def calculate_information_gain(X, y, feature):\n",
    "    total_entropy = calculate_entropy(y)\n",
    "    values, counts = np.unique(X[feature], return_counts=True)\n",
    "    weighted_entropy = np.sum([(counts[i] / np.sum(counts)) * calculate_entropy(y[X[feature] == values[i]]) for i in range(len(values))])\n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain\n",
    "\n",
    "def find_root_node(X, y):\n",
    "    information_gains = {feature: calculate_information_gain(X, y, feature) for feature in X.columns}\n",
    "    root_node = max(information_gains, key=information_gains.get)\n",
    "    return root_node\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('ICICI_BANK.csv')\n",
    "data.describe()\n",
    "data.shape\n",
    "data.isnull().sum()\n",
    "data = data.dropna()\n",
    "data.isnull().sum()\n",
    "\n",
    "# Encode target variable based on price movement\n",
    "data['Target'] = np.where(data['Close'] > data['Open'], 1, 0)\n",
    "\n",
    "# Define features and target variable\n",
    "X_project = data[['Open']]\n",
    "y_project = data[['Target']]\n",
    "\n",
    "# Find the root node feature\n",
    "root_node_feature = find_root_node(X_project, y_project)\n",
    "print(\"Root Node Feature:\", root_node_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binned Open Feature:\n",
      " [3 3 3 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "def bin_continuous_feature(X, feature, num_bins=5, binning_type='equal_width'):\n",
    "    if binning_type == 'equal_width':\n",
    "        bins = np.linspace(X[feature].min(), X[feature].max(), num_bins + 1)\n",
    "        binned_feature = np.digitize(X[feature], bins)\n",
    "    elif binning_type == 'frequency':\n",
    "        bins = np.percentile(X[feature], np.arange(0, 100, 100 / num_bins))\n",
    "        binned_feature = np.digitize(X[feature], bins)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid binning type. Choose 'equal_width' or 'frequency'.\")\n",
    "    return binned_feature\n",
    "\n",
    "# Example usage of binning\n",
    "binned_open = bin_continuous_feature(X_project, 'Open', num_bins=5, binning_type='equal_width')\n",
    "print(\"Binned Open Feature:\\n\", binned_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_4032\\404267423.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[root_node_feature] = bin_continuous_feature(X, root_node_feature, num_bins=self.num_bins, binning_type=self.binning_type)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Example usage of Decision Tree\u001b[39;00m\n\u001b[0;32m     47\u001b[0m dt \u001b[38;5;241m=\u001b[39m DecisionTree(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, binning_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequal_width\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_project\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_project\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m predictions \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mpredict(X_project)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, predictions)\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m, in \u001b[0;36mDecisionTree._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     23\u001b[0m     X_subset \u001b[38;5;241m=\u001b[39m X[X[root_node_feature] \u001b[38;5;241m==\u001b[39m value]\n\u001b[0;32m     24\u001b[0m     y_subset \u001b[38;5;241m=\u001b[39m y[X[root_node_feature] \u001b[38;5;241m==\u001b[39m value]\n\u001b[1;32m---> 25\u001b[0m     sub_trees[value] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_node_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: root_node_feature, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_trees\u001b[39m\u001b[38;5;124m'\u001b[39m: sub_trees}\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mDecisionTree._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     13\u001b[0m     leaf_node \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39mbincount(y)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(y)}\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leaf_node\n\u001b[1;32m---> 16\u001b[0m root_node_feature \u001b[38;5;241m=\u001b[39m \u001b[43mfind_root_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X[root_node_feature]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;129;01mor\u001b[39;00m X[root_node_feature]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mint64:\n\u001b[0;32m     18\u001b[0m     X[root_node_feature] \u001b[38;5;241m=\u001b[39m bin_continuous_feature(X, root_node_feature, num_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins, binning_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinning_type)\n",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m, in \u001b[0;36mfind_root_node\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_root_node\u001b[39m(X, y):\n\u001b[0;32m     18\u001b[0m     information_gains \u001b[38;5;241m=\u001b[39m {feature: calculate_information_gain(X, y, feature) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mcolumns}\n\u001b[1;32m---> 19\u001b[0m     root_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minformation_gains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minformation_gains\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m root_node\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, num_bins=5, binning_type='equal_width'):\n",
    "        self.max_depth = max_depth\n",
    "        self.num_bins = num_bins\n",
    "        self.binning_type = binning_type\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            leaf_node = {'label': np.argmax(np.bincount(y)), 'samples': len(y)}\n",
    "            return leaf_node\n",
    "        \n",
    "        root_node_feature = find_root_node(X, y)\n",
    "        if X[root_node_feature].dtype == np.float64 or X[root_node_feature].dtype == np.int64:\n",
    "            X[root_node_feature] = bin_continuous_feature(X, root_node_feature, num_bins=self.num_bins, binning_type=self.binning_type)\n",
    "\n",
    "        unique_values = np.unique(X[root_node_feature])\n",
    "        sub_trees = {}\n",
    "        for value in unique_values:\n",
    "            X_subset = X[X[root_node_feature] == value]\n",
    "            y_subset = y[X[root_node_feature] == value]\n",
    "            sub_trees[value] = self._build_tree(X_subset.drop(root_node_feature, axis=1), y_subset, depth + 1)\n",
    "        \n",
    "        return {'feature': root_node_feature, 'sub_trees': sub_trees}\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            predictions.append(self._predict_row(row, self.tree))\n",
    "        return predictions\n",
    "\n",
    "    def _predict_row(self, row, tree):\n",
    "        if 'label' in tree:\n",
    "            return tree['label']\n",
    "        else:\n",
    "            feature_value = row[tree['feature']]\n",
    "            if feature_value in tree['sub_trees']:\n",
    "                return self._predict_row(row, tree['sub_trees'][feature_value])\n",
    "            else:\n",
    "                # Handle unseen feature values by predicting the majority class\n",
    "                return np.argmax(np.bincount(y_project))\n",
    "\n",
    "# Example usage of Decision Tree\n",
    "dt = DecisionTree(max_depth=3, num_bins=5, binning_type='equal_width')\n",
    "dt.fit(X_project, y_project)\n",
    "predictions = dt.predict(X_project)\n",
    "print(\"Predictions:\\n\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
