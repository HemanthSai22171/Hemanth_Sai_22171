{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a function to calculate the Euclidean distance and Manhattan distance between two vectors. The vectors dimension is variable. Please don’t use any distance calculation functions available in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUCLIDEAN DISTANCE :  5.196152422706632\n",
      "MANHATTAN DISTANCE :  9\n"
     ]
    }
   ],
   "source": [
    "def Euclidean_Distance(V1,V2):\n",
    "    if len(V1) != len(V2):\n",
    "        print(\"Both vectors are not of same length\")\n",
    "    \n",
    "    distance=0\n",
    "    for i in range(len(V1)):\n",
    "        distance += (V1[i]-V2[i])**2\n",
    "    return distance**0.5\n",
    "\n",
    "def Manhattan_Distance(V1,V2):\n",
    "    if len(V1) != len(V2):\n",
    "        print(\"Both vectors are not of same length\")\n",
    "    \n",
    "    distance=0\n",
    "    for i in range(len(V1)):\n",
    "        distance += abs(V1[i]-V2[i])\n",
    "    return distance\n",
    "\n",
    "V1 = [1, 2, 3]\n",
    "V2 = [4, 5, 6]\n",
    "print(\"EUCLIDEAN DISTANCE : \", Euclidean_Distance(V1,V2))\n",
    "print(\"MANHATTAN DISTANCE : \", Manhattan_Distance(V1,V2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write a function to implement k-NN classifier. k is a variable and based on that the count of neighbors should be selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: extra large\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_euclidean_distance(v1, v2):\n",
    "    if len(v1) != len(v2):\n",
    "        return math.inf  \n",
    "    sum_of_squares = 0\n",
    "    for i in range(len(v1)):\n",
    "        sum_of_squares += (v1[i] - v2[i]) ** 2\n",
    "    return math.sqrt(sum_of_squares)\n",
    "\n",
    "def find_neighbors(training_data, test_instance):\n",
    "    distances = []\n",
    "    for train_data in training_data:\n",
    "        distance = calculate_euclidean_distance(train_data[0], test_instance)\n",
    "        distances.append((distance, train_data[1]))\n",
    "    return distances\n",
    "\n",
    "def k_NN_classifier(training_data, test_instance, k_value):\n",
    "    neighbors = find_neighbors(training_data, test_instance)\n",
    "    neighbors.sort()\n",
    "    nearest_neighbors = neighbors[:k_value]\n",
    "    classes = [neighbor[1] for neighbor in nearest_neighbors]\n",
    "    class_counter = Counter(classes)\n",
    "    most_common_class = class_counter.most_common(1)[0][0]\n",
    "    return most_common_class\n",
    "\n",
    "training_data = [\n",
    "    ([150, 50], 'medium'), \n",
    "    ([155, 55], 'medium'), \n",
    "    ([160, 60], 'large'), \n",
    "    ([161, 59], 'large'), \n",
    "    ([158, 65], 'large'),\n",
    "    ([170, 70], 'large'),\n",
    "    ([180, 75], 'extra large'),\n",
    "    ([190, 80], 'extra large'),\n",
    "    ([200, 85], 'extra large'),\n",
    "    ([210, 90], 'extra large')\n",
    "]\n",
    "\n",
    "test_instance = [185, 78]  \n",
    "k_value = 3\n",
    "\n",
    "predicted_class = k_NN_classifier(training_data, test_instance, k_value)\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: extra large\n"
     ]
    }
   ],
   "source": [
    "def test_k_NN_classifier():\n",
    "    training_data = [\n",
    "        ([150, 50], 'medium'), \n",
    "        ([155, 55], 'medium'), \n",
    "        ([160, 60], 'large'), \n",
    "        ([161, 59], 'large'), \n",
    "        ([158, 65], 'large'),\n",
    "        ([170, 70], 'large'),\n",
    "        ([180, 75], 'extra large'),\n",
    "        ([190, 80], 'extra large'),\n",
    "        ([200, 85], 'extra large'),\n",
    "        ([210, 90], 'extra large')\n",
    "    ]\n",
    "\n",
    "    test_instance = [185, 78]  \n",
    "    k_value = 3\n",
    "\n",
    "    expected_class = 'extra large'\n",
    "\n",
    "    predicted_class = k_NN_classifier(training_data, test_instance, k_value)\n",
    "\n",
    "    print(\"Predicted class:\", predicted_class)\n",
    "    assert predicted_class == expected_class\n",
    "\n",
    "test_k_NN_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Write a function to convert categorical variables to numeric using label encoding. Don’t use any existing functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audi', 'bugatti', 'dodge']\n",
      "Label Encoded Values :  [0, 1, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def Label_Encoding(data):\n",
    "    unique_values = []\n",
    "    for val in data:\n",
    "        if val not in unique_values:\n",
    "            unique_values.append(val)\n",
    "    \n",
    "    print(unique_values)\n",
    "\n",
    "    encoding = {}\n",
    "    index = 0\n",
    "    for val in unique_values:\n",
    "        encoding[val] = index\n",
    "        index += 1\n",
    "\n",
    "    encoded_data = []\n",
    "    for val in data:\n",
    "        encoded_data.append(encoding[val])\n",
    "\n",
    "    return encoded_data\n",
    "\n",
    "categorical_data = ['audi', 'bugatti', 'audi', 'dodge', 'bugatti']  \n",
    "print(\"Label Encoded Values : \",Label_Encoding(categorical_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write a function to convert categorical variables to numeric using One-Hotencoding. Don’t use any existing functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audi', 'bugatti', 'dodge']\n",
      "[1, 0, 0]\n",
      "[0, 1, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def One_Hot_Encoding(data):\n",
    "    unique_values = []\n",
    "    for val in data:\n",
    "        if val not in unique_values:\n",
    "            unique_values.append(val)\n",
    "    \n",
    "    print(unique_values)\n",
    "\n",
    "    encoding = {}\n",
    "    index = 0\n",
    "    for val in unique_values:\n",
    "        encoding[val] = [0] * len(unique_values)\n",
    "        encoding[val][index] = 1\n",
    "        index += 1\n",
    "\n",
    "    encoded_data = []\n",
    "    for val in data:\n",
    "        encoded_data.append(encoding[val])\n",
    "\n",
    "    return encoded_data\n",
    "\n",
    "categorical_data = ['audi', 'bugatti', 'audi', 'dodge', 'bugatti']  \n",
    "encoded_list = One_Hot_Encoding(categorical_data)\n",
    "\n",
    "encoded_matrix = []\n",
    "for x in encoded_list:\n",
    "    encoded_matrix.append(list(x))\n",
    "\n",
    "for row in encoded_matrix:\n",
    "    print(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
